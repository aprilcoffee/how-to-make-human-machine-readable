{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook is the base of the code for the artwork [EIN STÜCK „LYRIK“: AUTOPOESIE APPARATUS FÜR ANTIKAPITALISTISCHE WERBEMITTEL](https://exmediawiki.khm.de/exmediawiki/images/3/35/KI-Plakat.pdf) from our former student [Verena Lercher](http://www.verenalercher.com/)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation mit LSTM\n",
    "\n",
    "\n",
    "## Implementierung der LSTM-Texterzeugung für Zeichen\n",
    "![](./data/character-level_neural_language_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten\n",
    "\n",
    "laden und konvertieren in 'lowercase':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge des Textkorpus: 462081\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "#eigenes textfile (in UTF-8)\n",
    "text = open(\"./data/KeinerWeissMehr.txt\").read().lower()\n",
    "print('Länge des Textkorpus:', len(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "umschreiben...:\n",
    "1. sequenzen mit der länge `maxlen` extrahieren\n",
    "2. mit `one-hot-encoding` in numpy-array `x` umwandeln\n",
    "3. numpy-array mit der `Shape(sequences, maxlen, unique_characters)` speichern\n",
    "4. numpy-array `y` für zielwerte vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Sequenzen: 154007\n",
      "Anzahl der in diesem Text verwendeten Zeichen: 53\n",
      "Vektorisierung...\n"
     ]
    }
   ],
   "source": [
    "# Exraktion von 60-Zeichen-Sequenzen\n",
    "maxlen = 60\n",
    "\n",
    "# sampling einer neuen sequenz nach jeweils 3 zeichen\n",
    "step = 3\n",
    "\n",
    "# speichern der extrahierten sequenzen\n",
    "sentences = []\n",
    "\n",
    "# speichern der zielwerte (der vorhergesagten zeichen)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Anzahl der Sequenzen:', len(sentences))\n",
    "\n",
    "# Liste der unterschiedlichen Zeichen erstellen\n",
    "chars = sorted(list(set(text)))\n",
    "print('Anzahl der in diesem Text verwendeten Zeichen:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# one-hot Kodierung in binäre Arrays\n",
    "print('Vektorisierung...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN erzeugen\n",
    "\n",
    "1. ein einzelner `LSTM` layer \n",
    "2. ein `Dense` Klassifizierer\n",
    "3. Berechnung der softmax-Funktion aller möglichen Zeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Zielwerte one-hot encoded wurden, \n",
    "benutzen wir `categorical_crossentropy` als Verlustfunktion um das Netz zu trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "optimizer = optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainieren des Sprachmodells und Sampling\n",
    "\n",
    "Mit trainierten Modell und einem kleinen Anfangstext neue Texte erzeugen...:\n",
    "\n",
    "1. Wahrscheinlichkeitsverteilung (anhand bereits erzeugten Textes) für das nächste Zeichen erzeugen\n",
    "2. Neugewichtung für eine bestimmte Temperatur durchführen\n",
    "3. das nächste Zeichen erzeugen\n",
    "4. das neue Zeichen am Ende des Textes hizufügen\n",
    "\n",
    "Code zur Neugewichtung und zum Abrufen eines Zeichenindex (Sampling-Funktion):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally - Das Modell trainieren und Text erzeugen\n",
    "\n",
    "nach jeder Epoche verschieden Temperaturen verwenden\n",
    "\n",
    "*...zum beobachten wie sich der erzeugte Text entwickelt und wie sich die verschiedenen Temperaturen der Sampling-Stratgie auswirken:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1204/1204 [==============================] - 140s 115ms/step - loss: 1.8710\n",
      "--- Erzeuge Text mit dem Anfangswert: \"int? man kann da nichts mehr machen, glaub mir, ein winziger\"\n",
      "------ Temperatur: 0.2\n",
      "int? man kann da nichts mehr machen, glaub mir, ein winziger das war es war auf den er sich auf der stehen, das war es war er sich sich das war das war auf die schlaffen, das zu sehen, das war er so war er sich so war es war es war das war sie sich auf der schließlich sich das war war er sich so war es war das soch das war er so das war das war er sich das gehonten war es war das war es war es war er sich das war es war es war er sich das zu sehen war das \n",
      "------ Temperatur: 0.5\n",
      " er sich das war es war es war er sich das zu sehen war das war er wal es nach sie sich das zu den hautend sich auch bis ihm so das das war es war das stell, was das war das und das war aus diesen war sie war, was als das vorber hiere sich vorberen wollte, das war so das war sagen so war das auf der schwielig auch ein zimmer wos, das das ger mehren das zu scheigen wollte sie so neben stelle, was ein weit ausgenommen sehen, ihne auf der stehen, das auf der \n",
      "------ Temperatur: 1.0\n",
      "in weit ausgenommen sehen, ihne auf der stehen, das auf der schwechen auf die rücken noch weiß auf, das sol stramne. diese angeselr, vocher fanke ein stocsen und sommertem durch zu genommen wetzig und frau nochmal. auf den rahn\n",
      "gegohnterr mit weiter daschtend, das rochen nichts waren war es zu allee, jetzt in dieselben in seimeste, das waß der an den so und\n",
      "sort einet, als rießlich zwei tagben auf, dan bild so war, alle der auf, das, einem dawuhrend\n",
      "drauße\n",
      "------ Temperatur: 1.2\n",
      ", dan bild so war, alle der auf, das, einem dawuhrend\n",
      "draußen. do tachtnum aroankauffälffen, einfachsamitok. ein weg? noch\n",
      "nichts\n",
      "war für ir gehen, dasam mal dasikal zter duron letielb nach ihn zus stensich wes.\n",
      "das gehaleluertamist dareurozig anze, neinselt das wenig zum bliebe in, soch,\n",
      "verschweistätigen vorlart\n",
      "etzis, drettemzeuch, wolit danu, nur ale, trättiligen\n",
      "sie küste forten, nie hächtetengegone  verscekt war, eine war wohnurch wollse\n",
      "tböchshank, \n",
      "epoch 2\n",
      "1204/1204 [==============================] - 137s 114ms/step - loss: 1.5323\n",
      "--- Erzeuge Text mit dem Anfangswert: \" zwang, sie\n",
      "zu hassen, denn dann konnte sie ihm direkt vorwe\"\n",
      "------ Temperatur: 0.2\n",
      " zwang, sie\n",
      "zu hassen, denn dann konnte sie ihm direkt vorwein sie sich das geschien war, die er zu seinen auf den schiel dem beinen schien in den anderen schiel die beinen schiel geschieren warden war, die schien in den er schien die frau das geschier war, die schien der schien die beinen schiel dem traubenden schiel die beinen stelle die schien die beinen schiel dem beinen auf den er die schiel die schiel die er den nicht mehr schien in den en schien das\n",
      "------ Temperatur: 0.5\n",
      "die schiel die er den nicht mehr schien in den en schien das und dann nicht mehr das tragen kleinen gestellt wieder den anderen, das kann, oder in einem aufgekommen war, die auf den treinen zu abteichen, kümmer wegt, die breiten einzelten, aufgefillen, denn sich und das, sehr nicht genig zu wenig bewegen zu saft, die verwirrt hatte, wenn du diesen auszu den aufgezogen, und aufgerichten hatte, die sie beiden auf dem mitzen können mit einem beinen, wieder ge\n",
      "------ Temperatur: 1.0\n",
      "sie beiden auf dem mitzen können mit einem beinen, wieder genöult,\n",
      "eben und und im rein der tisch verstellt, gesehrt nicht durchs. er mleier odern geherzeitetzeg trag hier diesen\n",
      "tieck und verrosen, verstand,\n",
      "hochläche, denn spakten hand aufgerungter seiner. dem rasih er\n",
      "du bewohnschinkreder busdigkenten unwegse, offen in dehen binden, büch und heradtsagen, nicht dmewen dieme verschaft unäugin sehen müschen, in\n",
      "der ahnziehon, ein,\n",
      "wurden auseinmach, je in \n",
      "------ Temperatur: 1.2\n",
      "en müschen, in\n",
      "der ahnziehon, ein,\n",
      "wurden auseinmach, je in diesenopfer de\n",
      "st diehen, dem bliemopenmalben noch von im von mfemstölligs. bar wie rat gereckt war bunuligen, ein entifrenfall, etzwprktorten zumerpt. das zem banahin dieserom retzuschütt. sal npür, um hruhten. zu engs zied, bid unwiden, iggerin, unru die fön slich scheit, die spaß fälls sich diche neand. er wossighwieren, im blickte nochwägen, soisen, neu weiß, so za in ihm beraue\n",
      "ver cen stand \n",
      "epoch 3\n",
      "1204/1204 [==============================] - 149s 124ms/step - loss: 1.4427\n",
      "--- Erzeuge Text mit dem Anfangswert: \"m verschwunden, sie, seine\n",
      "frau, sauber und gepflegt und hüb\"\n",
      "------ Temperatur: 0.2\n",
      "m verschwunden, sie, seine\n",
      "frau, sauber und gepflegt und hübsch, das sich eingestreckt hatte, das eine anderen bewegungen war, das schien auch das haus auf dem bahnen stadt und seine abende stadt, und sie stehen sollen hatte, das ausgekommen war. ein stadt war. auf dem baut aufheilten stadt hinter den schaufenster, das sich seine geschwitzt hatte, aus dem anderen stand, den stelle ausgestreckt hatte, das geschwitzt, so und das keinen stadt auf dem anderen.\n",
      "------ Temperatur: 0.5\n",
      "te, das geschwitzt, so und das keinen stadt auf dem anderen. er saß, sich neben seiten anderen bewegungen und seine bewegung, dieses weiße, das auf\n",
      "und sagen. nicht nach,\n",
      "am tauch schon einwarden aus dem tagen haben hatten gegen ihren aus, zu haben, seine stadt aufhallen\n",
      "der enden ausgelegte, war sie hatte eine immer beschäftig hinder stelle schon ausgehen\n",
      "ingenehn und seine cochen anderen\n",
      "fraute. er hatte nicht mit denken mit dem anderen bewegung eingesic\n",
      "------ Temperatur: 1.0\n",
      " er hatte nicht mit denken mit dem anderen bewegung eingesicht\n",
      "schiedenhagen, hielt ihren ihm pell helzstehbt. kleiden, sonse,\n",
      "daängenommen geralden war.\n",
      "aus einnewetwanise frauen, henkunt, das. kappt aufprilierst aus einer. deines zimmer ge\n",
      "und in\n",
      "einen abganzicht, gaut nicht das es\n",
      "bestemmt. auf tick, nur noch wall, wahren, zweimer reibrett irm, vom tür tranen aufgezedlen. soglliegen\n",
      "und und denkon, in\n",
      "diesem toll in dieser\n",
      "sagen,\n",
      "fahre diese  seine la v\n",
      "------ Temperatur: 1.2\n",
      "kon, in\n",
      "diesem toll in dieser\n",
      "sagen,\n",
      "fahre diese  seine la vchen, um ier wieder an ihme stehlee. durch ihnep\n",
      "ieroßelns\n",
      "graden las, weich smit ausen vittelnsam. ja\n",
      "kein ihmer, das unterkassen, da, rätde, saubtö-mir ruh. auch manz, einstenst der zinger und\n",
      "wehlte ihrbleubleichen austorziehen sigen, wieder tatfaän. eorrüften würde und aller nieman.\n",
      "zugeckenaal g, dem, es enkonft ruch, er sat. sie ständlich, ack, abfautlaft moroen\n",
      "hingeörmenügen lenn laren dac\n",
      "epoch 4\n",
      "1204/1204 [==============================] - 152s 126ms/step - loss: 1.3892\n",
      "--- Erzeuge Text mit dem Anfangswert: \"zusammen zu erreichen wäre, bis\n",
      "sie dann, je mehr sie sich d\"\n",
      "------ Temperatur: 0.2\n",
      "zusammen zu erreichen wäre, bis\n",
      "sie dann, je mehr sie sich das sich das war eine frau, das war das sich das war das geschwanden stelle sich das seine beinen stand haben sich auf dem bewegungen war schon ein schwer das so seine frau sich das so weiter schwere zu sich vor ihnen stand in einem zu streigt hatte, sich das geschwellende schwere zu stellen schon das so dachte er sich das sich das sich seine straße schwere zu stand zu streigen war eine glauben sic\n",
      "------ Temperatur: 0.5\n",
      "ine straße schwere zu stand zu streigen war eine glauben sich prau eine geschwanden, ich nichts mehr das die hellen ihn dann eine zugehen und den beide halb denken zu spaßen nachmittags sich das das schon auf der aus dem bauch\n",
      "das mußte sich schand seinen stand zusammengloß und das einfach schon war weiter konnte, sondte er auf dem felden schlecht mit dem weichen, mit einem schallplatten. er sagt mit der winter schon eine gleiben aus dem schwankend, so daß\n",
      "------ Temperatur: 1.0\n",
      "mit der winter schon eine gleiben aus dem schwankend, so daß man sich völlig waren nebenbewegt vor den nebeche kleiderheite gedränte seibe ihn immes zu beine, wag sie setzen, seine scuhneken surdhalt mit dem rünken. versußte, was dachte ernendlich zu sehen. undem aus machen, und von wimpzig einfilder wichtigem hochauser vor den dacken wind zusammenglicbtset, und daman g, nichts getrochen waren, die stelle mitteln, und sowein\n",
      "schrub auf die tisch die wechen\n",
      "------ Temperatur: 1.2\n",
      "e stelle mitteln, und sowein\n",
      "schrub auf die tisch die wechenstaden\n",
      "und sommer auch bsitt, nebenlag raus, zwand eingeß rückstäutigtig weisrden über\n",
      "aus . dägist immerzufangtes, im buck zu fahren tat am trisi, erscheimftend steisen zogstell. erkranmen mißte, durch machte.\n",
      "man sch eine leuten andrenen plöckst\n",
      "diese. wüsch von mocht das, lag, was milches was, zufahren,\n",
      "pahm\n",
      "nur dann man schären\n",
      "in einer lemacht häusen kätten, die aus der buch im arfeinen\n",
      "plätt\n",
      "epoch 5\n",
      "1204/1204 [==============================] - 127s 105ms/step - loss: 1.3488\n",
      "--- Erzeuge Text mit dem Anfangswert: \" man ohne aufzuhören wirklich leben konnte. so. er. sie. man\"\n",
      "------ Temperatur: 0.2\n",
      " man ohne aufzuhören wirklich leben konnte. so. er. sie. man stand auf dem schaben das schraufen sich zu seiten zu seiten sie sich das morgen sie sich das geschäftigt hatte, was er sich das sich das sich so schrimmer, das war das so daß er sich nicht gerald aus dem schallplattengeschäftigt hatte, sie war so nicht mehr das sich an der stadt wieder das sich aus dem kind das so so daß er sie sich das so das macht auch nicht auf der stelle sich das sich das ei\n",
      "------ Temperatur: 0.5\n",
      " so das macht auch nicht auf der stelle sich das sich das eine zeitlang hatte er sie so das man stand abends geschäftigt in der geschwarte, fall aufgeschneiten, das hauten sich das war es genau das eine nach hinten in dem man schreist du durchgeormaten zu seit sich weiter nicht mehr. sie aufgefahrt, das aus dem trau so spiel sich zu bewegung, das trat er mit einem tag, so daß er hatte sie zu spielten haute straßenfahrte sich seine stadt herausgeschreckt, w\n",
      "------ Temperatur: 1.0\n",
      "ten haute straßenfahrte sich seine stadt herausgeschreckt, was da land konnte sich wieselbe,\n",
      "welter, was schon jahatte sich der\n",
      "rühren, hope dabei musik\n",
      "die anwesen plänke,\n",
      "weiter sie sich heruntsig,\n",
      "stimm sie auch wenn und zu\n",
      "sprechen achse, so wie, und sich jetzt saß sie seine versehen, genauer krisier, davon, gut und\n",
      "die wohnze spielte, und von einem abfanden,\n",
      "wie er sich vorhande. es\n",
      "sag rainerwisch, dalie ausgefahrt, wieder nach daukräg und an,\n",
      "wie si\n",
      "------ Temperatur: 1.2\n",
      "rwisch, dalie ausgefahrt, wieder nach daukräg und an,\n",
      "wie sie mach, da mach zu abtikber, es macht, gingrothalten kurz, ,\n",
      "das lichtppaau daine. überhaupp auch, wäsch, daß dieser lautfällte zär waren bildig, eine erem, dasseu judi, die\n",
      "trateppauetunden gegen der som zwahrlosen mal cawäumen hute, schuhef oder. ob zu\n",
      "änderd gekatfen, umgebäumlen heulegt,\n",
      "er, solo ar immer noch mitbar er mie hinunt\n",
      "herum dasselveh pländikn, immer lenuts, noc den\n",
      "nicht, daß sind\n",
      "epoch 6\n",
      "1204/1204 [==============================] - 122s 102ms/step - loss: 1.3302\n",
      "--- Erzeuge Text mit dem Anfangswert: \"uerputz. hinter der mauer standen zurückgezogen und von hint\"\n",
      "------ Temperatur: 0.2\n",
      "uerputz. hinter der mauer standen zurückgezogen und von hinter der trecken zu sehen war, das war es sich nicht das kleinen stadt war, das er sich alle sich das war es sollte er sich aber es war es sich das sie sich selbst das er war es sich das er sich das sich war es nicht so ein weniger schlafen war, das sie sich aber wieder sich selbst er sich abgeschauseten stadt war, wieder ein stadt war es aber nicht alles war es sich nicht als er sich aber nicht so,\n",
      "------ Temperatur: 0.5\n",
      "ber nicht alles war es sich nicht als er sich aber nicht so, nie er sich aufgerossen war, wieder immer werder gewordenen stelle, die sie die straßen vor sich schon wieder der wäre er das gesicht war, wieder sich selbst aber das auf der thauben zurückgestelltet alles sich in der bestellt, wieder etwas gesicht, sie war es immer so, war es das kleinen zeitschrift, was ist es so ein abgebeigen hinter sich absichtigen straßen war, wenn er war werde er sich sich\n",
      "------ Temperatur: 1.0\n",
      "sich absichtigen straßen war, wenn er war werde er sich sich selbst er abgrücken mit dem abs, unspiel rainer. er habene\n",
      "warch, wie er, bünterhin abgeschneten worden.\n",
      "das hier an der entschnelter sich die körper als sie zu\n",
      "bebreieen war, nicht von nichts fett um. durchfällig falf am angesetzt war hier odem zu sachen, der moment hören er war es anisch. es nicht macht habste,\n",
      "ich ganz einem frauze, beschäftigt vollar der boder komme dasem. er stellte, das abz\n",
      "------ Temperatur: 1.2\n",
      "eschäftigt vollar der boder komme dasem. er stellte, das abzulicht da,  ndadente\n",
      "bahre ß. das\n",
      "war es nur immer beutens, mir, verbeschand gemacht. affrabs, zusicht und er zeit war es\n",
      "schor gering, santernahmtaubr oder wesier sagze. immer do\n",
      "so vergelenntes, eck, wogleich\n",
      "am antwermijches\n",
      "und\n",
      "eines mörger,\n",
      "aber,\n",
      "die dring\n",
      "in blicktüm einbettrinden, alss, aber immer sah konnte stamigerflochmal, obenßuzimme satzigeschieden\n",
      "immer gekäfmun worden und zurgwe wied\n",
      "epoch 7\n",
      "1204/1204 [==============================] - 133s 110ms/step - loss: 1.3090\n",
      "--- Erzeuge Text mit dem Anfangswert: \"ar, regte ihn auf, obgleich er genau wußte, daß es so nicht \"\n",
      "------ Temperatur: 0.2\n",
      "ar, regte ihn auf, obgleich er genau wußte, daß es so nicht mehr nicht mehr das genau von ihnen war das genau auf sich selbst das genau auf dem anderen straße hinter dem beinen straße hinter dem straße auf dem straße auf dem anderen straße auf dem anderen an den straße hinter dem straße hinter den straße an den eine straße vor ihm hinter den küche strecken gestellt, der stelle sich selbst das genau auf dem anderen straße an den straße hinter ihm war es nic\n",
      "------ Temperatur: 0.5\n",
      "u auf dem anderen straße an den straße hinter ihm war es nicht mehr auf dem stadt sich bereits seine vollen, das war es genau haben\n",
      "seine geworden war später, die an dem an der straße dahinter den gestellt, das lange angestanden, das war da war sich das schlecht, das starr genau genau daran das führ starr keinen auf dem darung, die war das war sie war es nicht nicht hinter sich auf dem anderen strecken, die bahrends sah, wo sie es gesehen, die sich nur wie\n",
      "------ Temperatur: 1.0\n",
      "ecken, die bahrends sah, wo sie es gesehen, die sich nur wieder, und er sehen, keinen gefühl hinter \n",
      "einem unten, also es hinter, das außen, jetzt war, bekliißen schnell, wiede er hiese zeit ohne zerönstreichlangen. nicht weit\n",
      "war ist errlicht blauelen viermwu-r auf bewegten.\n",
      "sie war drecken oder nach, um er schlecht gegendein zu hüterte in fleit während. er kranz\n",
      "weißen unter, er brauner nur da sehen, ohne daß er sie so neben mitteläklischen freien mußt. \n",
      "------ Temperatur: 1.2\n",
      "ehen, ohne daß er sie so neben mitteläklischen freien mußt. die an einem halb.\n",
      "leb später, weiter. er\n",
      "stadl regen, spürn, bilder, die stand, ver. arzubech, auch da, daß er sich\n",
      "noch lang\n",
      "kahlte, als meine, ein überallpete jenkf. dürlut, nicht, gab erro nicht, geräuschzlappict, den karedt hatten und in jeternetreckehen. sugschützte,\n",
      "keinen die mußte, swiederw. raine osig miten bei denkerig ab\n",
      "in, na. wenn und hich zu gesehen hatte, über esolent, das geembi \n",
      "epoch 8\n",
      "1204/1204 [==============================] - 147s 122ms/step - loss: 1.2922\n",
      "--- Erzeuge Text mit dem Anfangswert: \"stück, einen einfachen sekretär für ihre persönlichen kleine\"\n",
      "------ Temperatur: 0.2\n",
      "stück, einen einfachen sekretär für ihre persönlichen kleinen straße das kind das sich das war sie er sich ausgelassen, die sich aufgerissen war, das andere andere geschabtet hatten ihn zu sehen, das sich auf die straße auf dem kind hinter der straße streiter an der straße das gesagt, das andere andere aufgerascht hatte, als sie auch sehr stand aufgerissen, das sich ausgestrichen hatten ihn zu sehen hatte, das sich das schließlich alles sich aufgerichtet s\n",
      "------ Temperatur: 0.5\n",
      "en hatte, das sich das schließlich alles sich aufgerichtet sich vor der straße alles sie sich ausgestrichen war in sich selber darauf so seine sich das gesichter, das ein sam, das gerald ihn manchmal der trafe er sich seine frau, das auf den straße aufgerassen war, das spät in der straße in der seitenstumme bahren zu sehen haben, an die straße vor ihr auf die weiße gesacht hatten ersteht war das zu sehen war, ein straße aufbreckt hatte, worauf sie zusammen\n",
      "------ Temperatur: 1.0\n",
      "u sehen war, ein straße aufbreckt hatte, worauf sie zusammengekläpbt geros, hübsligem bemüchte\n",
      "war nicht ganz anders das außender in zugehelde lustiger frau in vur\n",
      "von augenblick sie in\n",
      "gefößig zu sehen, um sich, anderen rals sich beruhrt, zu\n",
      "wiellezieren,\n",
      "die wischten, daß kam, der eine untersichselbörtlich, er saubformen und weißlich sie, selbst den seine dassel deren oder vierte lagen, auf dem sehende klappen\n",
      "ausgenommen wie gar nicht, mit der bahnfalls\n",
      "------ Temperatur: 1.2\n",
      "sehende klappen\n",
      "ausgenommen wie gar nicht, mit der bahnfalls neben ihnen die allethll man schließlich, worjs wo nicht, sie bei ihr, vom lengeln. sie hin grünee teisten\n",
      "gewoklen,\n",
      "sich hinter einem schwanz, aufgerenastebsile\n",
      "mats glaub\n",
      "wenjuttune zum sicht, er hatte abgerülebete in dieses alben, wares eingestrückt.\n",
      "das wäre dir stimmenheiten\n",
      "nackthmer feinam zörgen, um weicher unterherdiisit. was ich all don ja, ebeinge, fill abgeraldstpuvhein. sonst ging, v\n",
      "epoch 9\n",
      "1204/1204 [==============================] - 134s 112ms/step - loss: 1.2801\n",
      "--- Erzeuge Text mit dem Anfangswert: \" zusammenhängt, doch dieses eine mal meint\n",
      "man, es sei gründ\"\n",
      "------ Temperatur: 0.2\n",
      " zusammenhängt, doch dieses eine mal meint\n",
      "man, es sei gründe er sich das gestellt, das war er sich so daß er sich selbst du schließen als eine haustürchen ausgelegten streichen und das genau auf dem haus genauen geworden war, was er sich das war es nicht mehr auf dem stadt, wenn er sich weiter das genau auf dem bett und das sie sich das genau ausgedrückt, das sie sich nicht mehr an den beine standen und stelle, die sie sich das er sich das genau ausgedehn\n",
      "------ Temperatur: 0.5\n",
      "den und stelle, die sie sich das er sich das genau ausgedehnt,\n",
      "daß du einfach, so zu tagen und hinter ihm und daur geschwunden, das sie sich in den unkliej und er noch mittehiert hier einen bleichämmelt den los, weiter genausem sehr stand, das gesonderen glaubt, sie sich sehr zusammenhalten, während er auf die nackten haus genug. der nicht mehr das streifenden blieben das war er das sie einfach weg, das sie beide schließen einfache straße auf dem babenstau\n",
      "------ Temperatur: 1.0\n",
      "g, das sie beide schließen einfache straße auf dem babenstaust war du kannte, wenn winter maß, dero\n",
      "stehende leden, mitten, diese staften,\n",
      "nur leeerk, haumdokheit war, die mann durch sie\n",
      "er zeitschrigen,\n",
      "da war ihm sie, nicht tags,\n",
      "ganze können, er war weg sich daß immer weiter, es merkte, nachmittags ein stehenden untüchigungen,\n",
      ",\n",
      "das wintere dahr\n",
      "tag\n",
      "hasste licht, hhatte zom\n",
      "bün so einmal ein mann, das kind. du ist so ebens glatta sie, denke mit umistent\n",
      "------ Temperatur: 1.2\n",
      "nn, das kind. du ist so ebens glatta sie, denke mit umistentiot haar. in ihr reintot, ohne auf,\n",
      "zböstlich,\n",
      "winter mir balton, nachmitt gedehrngngesgingen\n",
      "war, eine wachelsgüstielten treckend, von ihm hert blauen\n",
      "zu fassen, nichts.\n",
      "du lächlich mehr seg aöfzig warte, so dann fand und wißtes genrald hahen-gmeinmal wie er erschriebenen haltungenhalt, das stritälte\n",
      "zug\n",
      "nicht erkt, das unstrenden mos, darauf und vorszehlagen\n",
      "schlief fürlich hintalos überd ihm wi\n",
      "epoch 10\n",
      "1147/1204 [===========================>..] - ETA: 7s - loss: 1.2648"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5e1a7073d040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Anpassung des Modells für einen Trainingsdurchlauf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     model.fit(x, y,\n\u001b[0m\u001b[1;32m      9\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               epochs=1)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "# Das Modell 60 Epochen lang trainieren\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Anpassung des Modells für einen Trainingsdurchlauf\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Zufällige Auswahl eines Anfangstexts\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Erzeuge Text mit dem Anfangswert: \"' + generated_text + '\"')\n",
    "    \n",
    "    # ausprobieren verschiedener Temperaturen\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ Temperatur:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # vom Anfangstext ausgehend 400 Zeichen erzeugen\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                # one-hot-codierung der schon erzeugten zeichen\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            # sampling des nächsten Zeichens\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
