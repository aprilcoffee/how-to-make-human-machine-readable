{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading / Scraping / Walking through Textcorpora as Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to get data...\n",
    "\n",
    "- [1. read file from your local system](#1)\n",
    "- [2. download Textfiles f.ex. from gutenberg.org](#2)\n",
    "- [2.1. in case your IP is blocked about any reason](#3)\n",
    "- [3. scraping (static) Textcorpora from the Darknet](#4)\n",
    "- [4. scraping (static) Textcorpora from the Web](#5)\n",
    "- [5. scraping PDF's from the Web](#6)\n",
    "- [6. scraping RSS Feeds](#7)\n",
    "- [7. Allison Parrish's Gutenberg Poetry Corpus](#8)\n",
    "- [8. al-Ready Datasets for Textprocessing](#9)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file from local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Geschichtenerzähler machen weiter. die Autoindustrie macht weiter. die Arbeiter machen weiter. d\n"
     ]
    }
   ],
   "source": [
    "#set variable\n",
    "filename = './data/alles-macht-weiter.txt'\n",
    "# open file\n",
    "file = open(filename, 'rt')\n",
    "#read it in\n",
    "amw1 = file.read()\n",
    "#close it\n",
    "file.close()\n",
    "#print the first 101 items\n",
    "print(amw1[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### download Textfiles f.ex. from gutenberg.org (Schuld und Sühne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org. If you are not located in the United States, you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this eBook\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import requests\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "\n",
    "#request the text\n",
    "r = requests.get(url)\n",
    "\n",
    "#print the first 527 characters\n",
    "print(r.text[0:527])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### in case your IP is blocked about any reason\n",
    "\n",
    "you can scrape f.ex. over the TOR-SOCKS Proxy like that (you have to have installed TOR first on your machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request: {\n",
      "  \"origin\": \"78.49.43.189\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"origin\": \"78.49.43.189\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "SOCKSHTTPConnectionPool(host='httpbin.org', port=80): Max retries exceeded with url: /ip (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f3e9333b580>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/socks.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Initial connection to proxy server.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocksocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyConnectionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/contrib/socks.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             conn = socks.create_connection(\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/socks.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/socks.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/socks.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/socks.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s due to: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProxyConnectionError\u001b[0m: Error connecting to SOCKS5 proxy localhost:9050: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/contrib/socks.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     raise NewConnectionError(\n\u001b[0m\u001b[1;32m    109\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.contrib.socks.SOCKSConnection object at 0x7f3e9333b580>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    431\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0m\u001b[1;32m    639\u001b[0m                                         _stacktrace=sys.exc_info()[2])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: SOCKSHTTPConnectionPool(host='httpbin.org', port=80): Max retries exceeded with url: /ip (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f3e9333b580>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c60c1439867c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#get the new IP adress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://httpbin.org/ip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: SOCKSHTTPConnectionPool(host='httpbin.org', port=80): Max retries exceeded with url: /ip (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f3e9333b580>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import requests\n",
    "\n",
    "#get your usual IP adress\n",
    "r = requests.get('http://httpbin.org/ip')\n",
    "print(\"request:\", r.text)\n",
    "\n",
    "#creating now an empty session object\n",
    "session = requests.session()\n",
    "session.proxies = {}\n",
    "\n",
    "#get your usual IP adress\n",
    "s = session.get('http://httpbin.org/ip')\n",
    "print(s.text)\n",
    "\n",
    "#adding TOR proxy\n",
    "session.proxies['http'] = 'socks5h://localhost:9050'\n",
    "session.proxies['https'] = 'socks5h://localhost:9050'\n",
    "\n",
    "#get the new IP adress\n",
    "t = session.get('http://httpbin.org/ip')\n",
    "print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get the data you'd like to scrape\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "t2 = session.get(url)\n",
    "print(t2.text[0:527])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "###  if you wanna scrape Textcorpora like that (in HTML-Format) from the Darknet\n",
    "\n",
    "* List of Librairies in the darknet: http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/wiki/Libraries\n",
    "* The Hidden Wiki: http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/wiki/index.php/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the WebURL with an Onion-Adress\n",
    "dw = session.get('http://libraryqtlpitkix.onion/library/Fiction/Stanislaw%20Lem%20-%20GOLEM%20XIV.txt')\n",
    "#print(dw.headers, \"\\n\")\n",
    "print(dw.text[0:1527])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Download (static) Textcorpora as (HTML) from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:my=\"mynames\" lang=\"de\"><!-- DEBUG start 22:39:30+01:00 page_id=4627 :: Netzökonomie--><!--\\n\\t\\tCo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"https://taz.de/Vorwuerfe-von-schwarzer-KI-Forscherin/!5730475/\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Vorwürfe von schwarzer KI-Forscherin: Proteste bei Google\n",
      "\n",
      "Die bekannte KI-Forscherin Timnit Gebru verlässt Google im Streit. Grund ist eine Studie zu Sprachverarbeitung, die dem Konzern nicht passt.\n",
      "Forscherin Timnit Gebru wirft ihrem Ex-Arbeitgeber Zensur vor  Foto: Kristin Callahan/ZUMA Press/imago\n",
      "Google liebt sein Image als uneigennütziger Tech-Konzern. Da passt es nicht gut ins Bild, wenn Tausende Mitarbeiter:innen protestieren und in einem offenen Bri\n",
      "['würden', 'damit', 'die', 'Umwelt', 'belasten', '.', 'Auch', 'könnten', 'derartige', 'Systeme', 'für', 'Desinformation', 'missbraucht', 'werden', '.', 'Google', 'wies', 'den', 'Entwurf', 'intern', 'zurück', ',', 'weil', 'er', 'angeblich', 'nicht', 'genügend', 'aktuelle', 'Studien', 'berücksichtige', '.', 'Wis\\xadsen\\xadschaft\\xadler', ':', 'in\\xadnen', 'sprechen', 'hingegen', 'von', 'Zensur', '.', 'In', 'der', 'Literaturliste', 'sind', 'indes', 'mehr', 'als', '128', 'Verweise', 'angeführt', '.', 'Schon', 'im', 'Jahr', '2019', 'hatte', 'Meredith', 'Whittaker', 'Google', 'im', 'Streit', 'verlassen', ',', 'auch', 'sie', 'arbeitete', 'im', 'Bereich', 'der', 'KI-Ethik', '.', 'Der', 'Eindruck', 'bleibt', ',', 'dass', 'Google', 'Mit\\xadar\\xadbei\\xadter', ':', 'in\\xadnen', ',', 'die', 'das', 'Geschäftsmodell', 'gefährden', 'und', 'Kritik', 'öffentlich', 'äußern', ',', 'loswerden', 'will', '.', 'Und', 'dabei', 'Kritik', 'aus', 'der', 'Wissenschaft', 'kleinredet', ',', 'wenn', 'sie', 'nicht', 'ins', 'Bild', 'passt', '.', 'Einmal', 'zahlen', '.', 'Fehler', 'auf', 'taz.de', 'entdeckt', '?', 'Wir', 'freuen', 'uns', 'über', 'eine', 'Mail', 'an', 'fehlerhinweis', '@', 'taz.de', '!', 'Inhaltliches', 'Feedback', '?', 'Gerne', 'als', 'Leser', '*', 'innenkommentar', 'unter', 'dem', 'Text', 'auf', 'taz.de', 'oder', 'über', 'das', 'Kontaktformular', '.', 'ÖkoNetzökonomie10', '.', '12', '.', '2020', 'Denis', 'Giessler', 'Autor', '*', 'in', 'ThemenGoogleAlgorithmenkünstliche', 'Intelligenz', 'mehr', 'vonDenis', 'Giessler', 'Abo', 'Tägliche', 'Sonderseiten', 'über', 'Gewinner', ':', 'innen', 'und', 'Verlierer', ':', 'innen', ',', 'sportlich', 'und', 'politisch', '.', 'Abo', 'inklusive', 'Spende', 'an', 'Human', 'Rights', 'Watch', '.', 'Treppchen', 'zum', 'AboVolle', 'Spalte', 'unterm', 'Artikel', 'Mehr', 'zum', 'ThemaGewerkschaftsgründung', 'bei', 'GoogleDie', 'Macht', 'des', 'KollektivsEine', 'Seltenheit', 'im', 'Silicon', 'Valley', ':', 'US-Beschäftigte', 'von', 'Google', 'haben', 'eine', 'Gewerkschaft', 'gegründet', '.', 'Ihr', 'Potenzial', 'sollte', 'nicht', 'unterschätzt', 'werden', '.', 'Daniél', 'KretschmarEnde', 'von', 'Adobe', 'FlashEin', 'Fall', 'für', 'den', 'MedienarchäologenAm', '31', '.', 'Dezember', 'stellt', 'Adobe', 'die', 'Unterstützung', 'für', 'die', 'Webtechnologie', 'Flash', 'ein', '.', 'Viel', 'Netzkreativität', 'ist', 'nun', 'dem', 'Untergang', 'geweiht', '.', 'Tilman', 'BaumgärtelMediengesetz', 'in', 'AustralienZahltag', 'für', 'Facebook', 'und', 'GoogleDigitale', 'Plattformen', 'sollen', 'Geld', 'für', 'Medieninhalte', 'zahlen', ',', 'die', 'sie', 'auf', 'ihren', 'Seiten', 'posten', '.', 'Entsprechende', 'Pläne', 'wurden', 'am', 'Dienstag', 'finalisiert', '.', 'Alle', 'Artikel', 'zum', 'Thema', 'Die', 'Kommentarfunktion', 'unter', 'diesem', 'Artikel', 'ist', 'geschlossen', '.', 'So', 'können', 'Sie', 'kommentieren', ':', 'Bitte', 'registrieren', 'Sie', 'sich', 'und', 'halten', 'Sie', 'sich', 'an', 'unsere', 'Netiquette', '.', 'Haben', 'Sie', 'Probleme', 'beim', 'Kommentieren', 'oder', 'Registrieren', '?', 'Dann', 'mailen', 'Sie', 'uns', 'bitte', 'an', 'kommune', '@', 'taz.de', 'Leser', '*', 'innenkommentareBudzylein10', '.', '12', '.', '2020', ',', '22:58Fazit', 'des', 'Artikels', ':', '``', 'Der', 'Eindruck', 'bleibt', ',', 'dass', 'Google', 'Mit\\xadar\\xadbei\\xadter', ':', 'in\\xadnen', ',', 'die', 'das', 'Geschäftsmodell', 'gefährden', 'und', 'Kritik', 'öffentlich', 'äußern', ',', 'loswerden', 'will', '.', \"''\", 'Ja', ',', 'so', 'ist', 'es', 'ganz', 'bestimmt', '.', 'Aber', 'mit', 'Verlaub', ':', 'Das', 'ist', 'bei', 'jedem', 'Unternehmen', 'so', '.', 'Die', 'wollen', 'niemanden', 'bezahlen', ',', 'der', 'ihr', 'Geschäftsmodell', 'gefährdet', '.', 'Und', 'öffentlich', 'geäußerte', 'Kritik', 'mag', 'auch', 'kein', 'Unternehmen', 'hören.Weber10', '.', '12', '.', '2020', ',', '21:42Google', 'rassistisch', '?', 'Really', '?', 'Der', 'Programmierer', 'James', 'Darmore', 'wurde', '2017', 'noch', 'wegen', 'eines', 'Memos', 'von', 'Google', 'gefeuert', ':', \"'Calling\", 'the', 'culture', 'at', 'Google', 'an', '``', 'ideological', 'echo', 'chamber', \"''\", ',', 'the', 'memo', 'states', 'that', 'while', 'discrimination', 'exists', ',', 'it', 'is', 'extreme', 'to', 'ascribe', 'all', 'disparities', 'to', 'oppression', ',', 'and', 'it', 'is', 'authoritarian', 'to', 'try', 'to', 'correct', 'disparities', 'through', 'reverse', 'discrimination', '.', 'Instead', ',', 'the', 'memo', 'argues', 'that', 'male', 'to', 'female', 'disparities', 'can', 'be', 'partly', 'explained', 'by', 'biological', 'differences', '.', '[', '1', ']', '[', '14', ']', 'Damore', 'said', 'that', 'those', 'differences', 'include', 'women', 'generally', 'having', 'a', 'stronger', 'interest', 'in', 'people', 'rather', 'than', 'things', ',', 'and', 'tending', 'to', 'be', 'more', 'social', ',', 'artistic', ',', 'and', 'prone', 'to', 'neuroticism', '(', 'a', 'higher-order', 'personality', 'trait', ')', '.', '[', '15', ']', 'Damore', \"'s\", 'memorandum', 'also', 'suggests', 'ways', 'to', 'adapt', 'the', 'tech', 'workplace', 'to', 'those', 'differences', 'to', 'increase', 'women', \"'s\", 'representation', 'and', 'comfort', ',', 'without', 'resorting', 'to', 'discrimination', '.', \"'\", 'en.wikipedia.org/w', '...', 'gical_Echo_ChamberAjuga10', '.', '12', '.', '2020', ',', '20:06Zu', 'solchen', 'Fällen', 'schweigen', 'die', '``', 'Antizensur-Aktivisten', \"''\", 'vom', 'Schlage', 'eines', 'Milo', 'Yiannopoulos', ',', 'Jordan', 'B.', 'Peterson', ',', 'Helen', 'Pluckrose', ',', 'Peter', 'Boghossian', ',', 'oder', 'dem', 'in', '4', 'Jahren', 'vom', '``', 'left-leaning', 'liberal', \"''\", 'zum', 'StopTheSteal-Vollverstrahlten']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "print(type(raw))\n",
    "print(raw[438:900])\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "print(tokens[300:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a tokenized copy of *text*,\n",
       "using NLTK's recommended word tokenizer\n",
       "(currently an improved :class:`.TreebankWordTokenizer`\n",
       "along with :class:`.PunktSentenceTokenizer`\n",
       "for the specified language).\n",
       "\n",
       ":param text: text to split into words\n",
       ":type text: str\n",
       ":param language: the model name in the Punkt corpus\n",
       ":type language: str\n",
       ":param preserve_line: An option to keep the preserve the sentence and not sentence tokenize it.\n",
       ":type preserve_line: bool\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.word_tokenize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### download PDF's from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# set URL\n",
    "url = \"https://www.christian-lindner.de/reden\"\n",
    "\n",
    "#If there is no such folder, create one automatically\n",
    "folder_location = r'./data/lindner-talks'\n",
    "if not os.path.exists(folder_location):os.mkdir(folder_location)\n",
    "\n",
    "#get all pdf's on this page and store it into the folder\n",
    "response = requests.get(url)\n",
    "soup= BeautifulSoup(response.text, \"html.parser\")     \n",
    "for link in soup.select(\"a[href$='.pdf']\"):\n",
    "    #Name the pdf files using the last portion of each link which are unique in this case\n",
    "    filename = os.path.join(folder_location,link['href'].split('/')[-1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(urljoin(url,link['href'])).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Processing RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feedparser\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#define the page to parse\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "#define what you want to see (the title of the feed-page):\n",
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much posts the page have?\n",
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a variable for the 3 post\n",
    "post = llog.entries[2]\n",
    "#print the title from it\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variable for its content\n",
    "content = post.content[0].value\n",
    "#print the first 71 items\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the html content with beautifulsoup as text\n",
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "#print it\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Allison Parrish's Gutenberg Poetry Corpus\n",
    "see: https://github.com/aparrish/gutenberg-poetry-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By [Allison Parrish](https://www.decontextualize.com/)\n",
    "\n",
    "Allison Parrish made a corpus of around three million lines of poetry from Project Gutenberg. In her notebook [A Project Gutenberg Poetry Corpus: Quick Experiments](https://github.com/aparrish/gutenberg-poetry-corpus/blob/master/quick-experiments.ipynb) she shows a couple of quick examples and experiments in using the corpus in Python. the following examples are from this notebook:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the corpus via this [link](http://static.decontextualize.com/gutenberg-poetry-v001.ndjson.gz) and store it in the same folder then this notebook is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is in gzipped [newline delimited JSON format](http://ndjson.org/): there's a JSON object on each line. You don't need to decompress the file to work with it, since Python has a handy library for working with gzipped files right in the code. The following cell will read in the file and create a list `all_lines` that contains all of these JSON objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 52.2M  100 52.2M    0     0  2914k      0  0:00:18  0:00:18 --:--:-- 2584k\n"
     ]
    }
   ],
   "source": [
    "# download it via `curl`\n",
    "##!curl -O http://static.decontextualize.com/gutenberg-poetry-v001.ndjson.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip it\n",
    "import gzip, json\n",
    "all_lines = []\n",
    "for line in gzip.open(\"gutenberg-poetry-v001.ndjson.gz\"):\n",
    "    all_lines.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'s': 'WHAT will you give me, O World, O World!', 'gid': '39032'},\n",
       " {'s': 'From thee in more than pristine beauty rise,', 'gid': '27663'},\n",
       " {'s': \"I ask'd my fair, one happy day,\", 'gid': '24815'},\n",
       " {'s': \"For o'er the crackling fire he heard\", 'gid': '214'},\n",
       " {'s': 'green for so hot a day.', 'gid': '13118'},\n",
       " {'s': 'Handsomest of all the people,', 'gid': '25953'},\n",
       " {'s': 'Too joyous to last,', 'gid': '19525'},\n",
       " {'s': 'A twelvemonth and a day,', 'gid': '27441'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract randomly lines of it\n",
    "import random\n",
    "random.sample(all_lines, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each object has a key `s` that contains the text of the line of poetry, and a key `gid` that contains the Project Gutenberg ID of the file in question. You can use this ID to look up the title and author of the book of poetry that the line came from (either using the [Project Gutenberg website](https://www.gutenberg.org/) or using pre-built metadata from, e.g., [Gutenberg, dammit](https://github.com/aparrish/gutenberg-dammit/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'s': 'The sound of fight is silent long', 'gid': '5720'}, {'s': 'That I must needs dismount, and search on foot', 'gid': '1365'}, {'s': \"Let's cut from all precedent loose,\", 'gid': '35033'}, {'s': \"Perhaps there's buried treasure out\", 'gid': '32553'}, {'s': 'Will enjoy the sunset, the pouring-in of the flood-tide, the', 'gid': '1322'}, {'s': \"And reach'd the Bay of Trinity, dark, lone,\", 'gid': '37365'}, {'s': 'Such witness yield; a monarch from his throne', 'gid': '4272'}, {'s': 'CCCXLI. To Mrs. Dunlop. Her friendship. A farewell', 'gid': '18500'}]\n",
      "～ ❀ ～\n",
      "['The sound of fight is silent long', 'That I must needs dismount, and search on foot', \"Let's cut from all precedent loose,\", \"Perhaps there's buried treasure out\", 'Will enjoy the sunset, the pouring-in of the flood-tide, the', \"And reach'd the Bay of Trinity, dark, lone,\", 'Such witness yield; a monarch from his throne', 'CCCXLI. To Mrs. Dunlop. Her friendship. A farewell']\n",
      "～ ❀ ～\n",
      "The sound of fight is silent long\n",
      "That I must needs dismount, and search on foot\n",
      "Let's cut from all precedent loose,\n",
      "Perhaps there's buried treasure out\n",
      "Will enjoy the sunset, the pouring-in of the flood-tide, the\n",
      "And reach'd the Bay of Trinity, dark, lone,\n",
      "Such witness yield; a monarch from his throne\n",
      "CCCXLI. To Mrs. Dunlop. Her friendship. A farewell\n"
     ]
    }
   ],
   "source": [
    "randompoem = random.sample(all_lines, 8)\n",
    "print(randompoem)\n",
    "print(\"～ ❀ ～\")\n",
    "\n",
    "randompoem_t = [line['s'] for line in randompoem]\n",
    "print(randompoem_t)\n",
    "print(\"～ ❀ ～\")\n",
    "\n",
    "randompoem_lb = \"\\n\".join(randompoem_t)\n",
    "print(randompoem_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "you could also f.ex. find in our random output a specific word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='sound'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dido = re.search('Dido', randompoem_lb)\n",
    "print(dido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The banquet-hall of Dido has remained throughout this recital in',\n",
       " 'Grant that it had been, whom should Dido dread,',\n",
       " 'because Dido is dead.]',\n",
       " \"Lo, such was Dido; joyously she bore herself e'en such\",\n",
       " \"Wars, and filial faith, and Dido's pyre;\",\n",
       " 'There now did Dido, Sidon-born, uprear a mighty fane',\n",
       " 'Now Dido leads',\n",
       " 'here!\" (577-661). Dido speaks him fair and echoes his words, \"If']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or finding a specific word in the whole document an printing the whole line (or 8 of it) \n",
    "dido_line = [line['s'] for line in all_lines if re.search('Dido', line['s'])]\n",
    "random.sample(dido_line, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# al-Ready Datasets for Textprocessing\n",
    "---\n",
    "\n",
    "import the `datasets` library from [huggingface](https://huggingface.co/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all information you'll need about that library, you will find here: https://pypi.org/project/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "1. Download the [Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "2. load the training split\n",
    "3. print the second training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/whoami/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [188], 'text': ['a copper statue of Christ']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f4190066117f', 'question': 'What is in front of the Notre Dame Main Building?', 'title': 'University_of_Notre_Dame'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "print(load_dataset('squad', split='train')[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
